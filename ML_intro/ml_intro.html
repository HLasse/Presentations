<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>ml_intro.utf8</title>
    <meta charset="utf-8" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/hygge.css" rel="stylesheet" />
    <link href="libs/tile-view/tile-view.css" rel="stylesheet" />
    <script src="libs/tile-view/tile-view.js"></script>
    <script src="libs/kePrint/kePrint.js"></script>
    <link href="libs/lightable/lightable.css" rel="stylesheet" />
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
    <link rel="stylesheet" href="../xaringan_columns/cols.css" type="text/css" />
    <link rel="stylesheet" href="../utils/hr_css.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">








class:  middle, title-slides

&lt;h1 style="margin-bottom: 0;"&gt; Introduction to Machine Learning &lt;/h1&gt;

&lt;hr&gt;
&lt;hr style="height:2pt; visibility:hidden;" /&gt;

![:col_row_title 
  &lt;i class="fas fa-user" aria-hidden="true" style="color:#003d73"&gt;&lt;/i&gt;  Lasse Hansen&lt;hr style="height:0.5pt; visibility:hidden;" /&gt;&lt;i class="fas fa-envelope" aria-hidden="true" style="color:#003d73"&gt;&lt;/i&gt;&lt;a href = "mailto: lasse.hansen@clin.au.dk"&gt; lasse.hansen@clin.au.dk&lt;/a&gt;, 
  &lt;i class="fa fa-map-marker-alt" aria-hidden="true" style="color:#003d73"&gt;&lt;/i&gt; ADA Journal Club&lt;hr style="height:0.5pt; visibility:hidden;" /&gt;&lt;i class="fa fa-calendar-alt" aria-hidden="true" style="color:#003d73"&gt;&lt;/i&gt; 25 May 2021, 
  ]


&lt;img src="../utils/aulogo_uk_var2_black.png"; style="max-width:250px;
position:absolute;left: 60px; bottom: 50px;"&gt;


&lt;img src="../utils/chc_long_tight.png"; style="max-width:250px;
position:absolute;right: 60px; bottom: 50px;"&gt;

---
class: inverse, center, middle

# Terminology


---
class: center, middle

&lt;img src="imgs/venn.jpg" height="500px" /&gt;


???
- the pop-sciency way of showing it
- logistic/linear regression are in the ML department
- Not how the terms are used by practioners
- why now? VAST AMOUNTS OF DATA
---

class: center, middle

&lt;img src="imgs/flowchart.png" height="500px" /&gt;


---

class: inverse, middle, center

# Rule-based Models


---

### Rule-based Models


.left-column[
&lt;img src="imgs/m1.png" height="500px" /&gt;
]

.right-column[
.large[Flowcharts and decision trees based on *__expert knowledge__* or *__learned from data__*.]

]


???
- clinical scoring scales are also an example

---

### Rule-based Models


.left-column[
&lt;img src="imgs/m1.png" height="500px" /&gt;
]

.right-column[
.large[Flowcharts and decision trees based on *__expert knowledge__* or *__learned from data__*.]

&lt;img src="imgs/decision_tree.png" width="500px" style="display: block; margin: auto;" /&gt;
]


???
- diabetes prediction based on blood glucose levels, insulin response etc.

---


class: inverse, middle, center

# Classic Machine Learning


---

### Classic Machine Learning

.left-column[
&lt;img src="imgs/m2.png" height="500px" /&gt;
]

.right-column[
.large[Models that learn from *__structured features__* such as what you find in the 
*__SFIs__* in the EHRs. ]

]


???
- height, weight, BMI, diagnoses, medicine taken, lab tests
- primarily tabular data

---

### Classic Machine Learning

.left-column[
&lt;img src="imgs/m2.png" height="500px" /&gt;
]

.right-column[
.large[Models that learn from *__structured features__* such as what you find in the *__SFIs__* in the EHRs. ]

&lt;img src="imgs/classifiers.png" width="500px" style="display: block; margin: auto;" /&gt;
]


???
- logistic/linear regression not shown here, but falls under the umbrella
- can easily deal with non-linearity


---

class: inverse, middle, center

# Representation/Deep Learning


---

### Representation Learning

.left-column[
&lt;img src="imgs/m3.png" height="500px" /&gt;
]

.right-column[
.large[Models *__create their own representation__* from raw input data]

]


???
- what does this mean? an example from CV

---

### Representation Learning

.left-column[
&lt;img src="imgs/m3.png" height="500px" /&gt;
]

.right-column[
.large[Models *__create their own representation__* from raw input data]

&lt;img src="imgs/cv_xray.png" width="300px" style="display: block; margin: auto;" /&gt;

]


???
- classical way: algorithmic segmentation -&gt; ML model
- learn features on its own! but how?

---

class: inverse, center, middle

# Neural Network Foundations


---

### Neural Network Foundations


.large[Multiple layers of *__non-linear__* processing]

&lt;img src="imgs/nn_arch.png" width="600px" style="display: block; margin: auto;" /&gt;


???
- multiple layers densely connected units
- input units take a pixel, word, SFI
- all units feed to the next where a non-linear function is applied to the weighted sum. This goes on for multiple layers until the output


---

### Neural Network Foundations

&lt;br&gt;

.pull-left[

&lt;img src="imgs/l1.png" width="50%" style="display: block; margin: auto 0 auto auto;" /&gt;

]

.pull-right[
&lt;img src="imgs/l2.png" width="50%" style="display: block; margin: auto auto auto 0;" /&gt;

]


---

### Neural Network Foundations

&lt;br&gt;

.pull-left[

&lt;img src="imgs/l3.png" width="50%" style="display: block; margin: auto 0 auto auto;" /&gt;

]

.pull-right[
&lt;img src="imgs/l4.png" width="50%" style="display: block; margin: auto auto auto 0;" /&gt;

]


???
transfer learning

---
class: inverse, center, middle

# Natural Language Processing

---
### Natural Language Processing

.large[Computers don't like working text. We need to convert it to numbers somehow.

Solution? Word vectors.
]

&lt;img src="imgs/nlp_vis.png" width="25%" style="display: block; margin: auto;" /&gt;


---
### Handcrafted Word vectors

.pull-left[
&gt; it was the best of times

&gt; it was the worst of times

&gt; it was the age of wisdom

&gt; it was the age of foolishness
]

.pull-right[
&lt;table class=" lightable-classic" style='font-family: "Arial Narrow", "Source Sans Pro", sans-serif; margin-left: auto; margin-right: auto;'&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:right;"&gt; best &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; the &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; times &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; was &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; worst &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; age &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; wisdom &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; foolishness &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
]

???
- Could also be word co-occurence, weighted by frequency of words etc.


---
### Handcrafted Word vectors

.pull-left[
&gt; it was the best of times

&gt; it was the worst of times

&gt; it was the age of wisdom

&gt; it was the age of foolishness


&lt;br&gt;

.large[
Context and semantics are completely disregarded!

Instead, train a deep learning model to learn *__contextualized word vectors__*
]


]

.pull-right[
&lt;table class=" lightable-classic" style='font-family: "Arial Narrow", "Source Sans Pro", sans-serif; margin-left: auto; margin-right: auto;'&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:right;"&gt; best &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; the &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; times &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; was &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; worst &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; age &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; wisdom &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; foolishness &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
]

---

### BERT

&lt;img src="imgs/bert.png" width="60%" style="display: block; margin: auto;" /&gt;

???
trained to find the masked item on hugo corpora
learns general structure of the language
essentially just a complex way of turning words into vectors of number
these vectors can be fed to any classifier

---
class: inverse, middle, center

# Take Home Messages

---
### Take Home Messages

.left-column[
### Machine Learning

]

.right-column[
- Learning from *__handcrafted features__*
- Encompasses a wide range of models, and very useful for most tasks
- Does not handle complex tasks like image or text analysis very well

]

---
### Take Home Messages

.left-column[
### Machine Learning

### Deep Learning
]

.right-column[
.fade[- Learning from *__handcrafted features__*
- Encompasses a wide range of models, and very useful for most tasks
- Does not handle complex tasks like image or text analysis very well]

&lt;br&gt;

- Creates meaningful features from raw input by itself
- Requires a lot of training data
- Very powerful, but can overfit if not careful
]

---
### Take Home Messages

.left-column[
### Machine Learning

### Deep Learning

### NLP
]

.right-column[
.fade[- Learning from *__handcrafted features__*
- Encompasses a wide range of models, and very useful for most tasks
- Does not handle complex tasks like image or text analysis very well

&lt;br&gt;

- Creates meaningful features from raw input by itself
- Requires a lot of training data
- Very powerful, but can overfit if not careful]

- How to turn text into meaningful representations for computers
- BERT learns *__contextualised word representations__* 
- *__Transfer learning__* is key to the success of deep learning and NLP
]


---
class: inverse, center, middle

# Questions?






???
Interpretability?

Did not mention:
- Overfitting
- Interpretatability





    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="../xaringan_columns/cols_macro.js"></script>
<script src="https://kit.fontawesome.com/f78b7b004e.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"ratio": "16:9",
"slideNumberFormat": "%current%",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
